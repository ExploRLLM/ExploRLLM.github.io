<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ExploRLLM: guiding Exploration in Reinforcement Learning with Language Models">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ExploRLLM: guiding Exploration in Reinforcement Learning with Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ExploRLLM: guiding Exploration in Reinforcement Learning with Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/runyu-ma-833bba256/">Runyu Ma</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/jelle-luijkx/">Jelle Luijkx</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/zlatanajanovic/">Zlatan AjanoviÄ‡</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://jenskober.de/">Jens Kober</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Delft University of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://github.com" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv(comming soon)</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://github.com" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video(comming soon)</span>
                </a>
              </span>
              <!-- Code Link(TODO). -->
              <span class="link-block">
                <a href="https://github.com" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(comming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <!-- <a href="https://github.com" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<div class="columns is-centered has-text-centered">
<div class="column is-four-fifths">
<video poster="" id="mask" autoplay controls muted loop playsinline width="75%" >
  <source src="./static/videos/ExploRLLM IROS.mp4"
          type="video/mp4">
</video>
</div>
</div>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%" >
            <source src="./static/videos/ExploRLLM IROS.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div> -->
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <p>
            We present ExploRLLM, a novel approach that combines
            the strengths of reinforcement learning with the knowledge
            from foundational models. 
          </p>
          <p>
            Reinforcement learning struggles with low sample efficiency, slow training speed, and uncertain convergence in large observation and action spaces for image-based robot manipulation policy learning. 
            As an alternative, large pre-trained foundation models have shown promise in robotic manipulation, particularly in zero-shot and few-shot applications. 
            However, using these models directly is unreliable due to limited reasoning capabilities and challenges in understanding physical and spatial contexts.
            To address these issues, we present ExploRLLM, a novel methodology that integrates the advantages of reinforcement learning with knowledge from foundational models.
            Our approach utilizes a reinforcement learning agent, equipped with a residual action space and observation space derived from affordances recognized by foundation models. 
            We leverage actions recommended by large language models to guide the exploration process, enhancing the learning strategy.
          <p>
            Our experiments demonstrate that this guided exploration facilitates much quicker convergence
            than training without. Additionally, we validate that integrating reinforcement learning with foundational models results in higher success rates and improved task performance thanfoundational models alone.
          </p> -->
          <p>
            Reinforcement learning struggles with low sample efficiency, slow training speed, and uncertain convergence in large observation and action spaces for image-based robot manipulation tasks.
            As an alternative, large pre-trained foundation models have shown promise in robotic manipulation, particularly in zero-shot and few-shot applications.
            However, using these models directly is unreliable due to limited reasoning capabilities and challenges in understanding physical and spatial contexts.
            Despite their limitations, the inferential capabilities of foundational models can serve as ``experts'' to inform and guide the reinforcement learning process. 
            This paper proposes ExploRLLM, a novel approach that combines the strengths of reinforcement learning with the knowledge from foundational models. 
            We use the actions suggested by large language models to direct the exploration process, significantly enhancing the efficiency of reinforcement learning and enabling robots to perform better than when relying solely on foundational models. 
            Our experiments demonstrate that this guided exploration facilitates much quicker convergence than training without. % the guidance of foundational models.
            Additionally, we validate that integrating reinforcement learning with foundational models results in higher success rates and improved task performance than foundational models alone. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <!--/ ExploRLLM. -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">ExploRLLM</h2>
          <p>
            ExploRLLM (guiding <b>Explor</b>ation in <b>R</b>einforcement <b>L</b>earning with <b>L</b>anguage <b>M</b>odels)is a novel methodology that integrates the advantages of reinforcement learning with knowledge from foundational models.
            Our approach utilizes a reinforcement learning agent, equipped with a residual action space and observation space derived from affordances recognized by foundation models. 
            We leverage actions recommended by large language models to guide the exploration process, enhancing the learning strategy.
          </p>
          <p>
            For the creation of plans in robotic manipulation tasks, prior research often prompts LLMs on every step to generate plans.
            However, this method of frequent LLM invocation during the training phase is highly resource-intensive, incurring significant time and financial costs due to the numerous iterations required to train a single RL agent. 
            Drawing inspiration from Code-as-Policy, our methodology employs the LLM to hierarchically generate language model programs, which are then executed iteratively during the training phase as exploratory actions, enhancing efficiency and resource utilization.
          </p>
          <img src="./static/images/figure1.png"
                 class="methodology"
                 alt="Interpolate start reference image."/>
        </div>
      </div>
  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Results</h2>
          <p>
            Experiments demonstrate that the exploration method significantly shortens RL's convergence time. 
            We also show that ExploRLLM outperforms the policies derived solely from the LLM and VLM.
          </p>
          <p>
            As the VLM has already extracted the observation space, the reinforcement learning agent trained within the simulation environment encounters fewer distractions from real-world noise.
            ExploRLLM approach still yields promising results for zero-shot applications using foundational models. 
          </p>

        </div>
      </div>

  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-simu">
          <video poster="" id="simu" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/simu_web.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-real-robot-experiment-video">
          <video poster="" id="realrobot" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/explorllm1.mp4"
                    type="video/mp4">
          </video>
        </div> 

        <div class="item real-robot-experiments-pic">
          <img src="./static/images/realrobot.png"
                 class="methodology"
                 alt="real robot experiments picture"/>
        </div>
        
        <div class="item plot_tb">
          <img src="./static/images/plot_tb.png"
                 class="methodology"
                 alt="training speed curve"/>
        </div>
        
        
      </div>
    </div>
  </div>
</section>





<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">nerfies</a> made by the <a
            href="https://github.com/keunhong">Keunhong Park</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
